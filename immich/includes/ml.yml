volumes:
  model-cache:

services:
  ml:
    container_name: immich-ml
    image: ghcr.io/immich-app/immich-machine-learning:v2-cuda # The -cuda here enables hardware acceleration
    env_file:
      - ../stack.env
    deploy:
      resources:
        limits:
          memory: 1G
        # Enables hardware acceleration
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities:
                - gpu
    volumes:
      - model-cache:/cache # This is just a cache of downloaded models, there's no need to keep it in a specific place or backup it up
    restart: unless-stopped